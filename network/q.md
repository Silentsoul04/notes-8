---
# time wait

在web00上看到很多time wait

今天测试了一下，用requests的session就可以解决这个问题 https://2.python-requests.org/en/v2.8.1/user/advanced/

---
# 为什么Go的web框架速度还不如Java

https://www.zhihu.com/question/360929863/answer/980246776

首先呢，Java也是编译型的语言。Java的编译分为两个步骤，第一步是从源代码到bytecode，也就是.class文件。我们日常看到的java jar包，其实就是bytecode的分发形式。第二步是在运行时，java虚拟机会和jit合作，把bytecode在需要的时候编译成native code。所以说呢，你这个链接里的跑分比较，其实大家跑的都是编译后的native code。

其次，web框架不单单要看中对语言的执行效率，还要看IO的效率。当然这也没什么花头，java的很多框架和go的异步IO如出一辙, 说白了还是借助linux操作系统中的epoll等来减少进程堵塞。于是很多跑分中，语言的执行效率变得次要，在充分优化和合理使用nonblocking IO的情况下，一些解释型语言也能取得很好的成绩。

最后，也是最重要的，其实你看这些跑分，框架的性能都好的不行不行的，远远超过一般应用的需要。其实在实际应用中，我们的业务逻辑会更复杂，上下游服务也会更多，其实就算是好多人瞧不起的增删改查操作，并发大了也极容易产生性能瓶颈。换句话说，编程语言和框架本身是不容易成为性能瓶颈的。所以，**我建议应该更多的从开发难易程度，以及以后项目长期维护的成本上来选择语言和框架，而不是看跑分**。

> 实际应用做，业务会更复杂。觉得不看重的增删改查，并发大了，也是有性能问题的。从开发难易程度，以及以后项目长期维护的成本上来选择语言和框架，而不是看跑分


[阿里巴巴淘系技术](https://www.zhihu.com/question/360929863/answer/1650981553)

第三点 prefork ， java netty 等是直接对于线程操作，可以更加定制化的优化性能，而 go 的 goroutine 需要的是一个通用协程，目的是降低编写并发程序的难度，在这个层次上难免性能比不上一个优化的非常出色的 Java 基于线程操作的框架；但是直接操作线程的话需要合理控制好线程数，这是个比较头疼的调优问题(特别是对于新手来说)，而 goroutine 则可以不关心池子的大小，使得代码更加优雅和简洁，这对于工程质量保障其实是一个提升。另外这里存在 prefork 是由于 go 没法直接操作线程，而 fasthttp 提供了 prefork 的能力，使用多进程方式来对标 Java 的多线程来进一步提高性能。

---
# time_wait

- [为什么 TCP 协议有 TIME_WAIT 状态](https://mp.weixin.qq.com/s/QTZJdxVzDNEvz7htDgGU-w):

## 阻止延迟数据段
为了保证新 TCP 连接的数据段不会与还在网络中传输的历史连接的数据段重复，TCP 连接在分配新的序列号之前需要至少静默数据段在网络中能够存活的最长时间，即 MSL
> 注意：指的是分配新的序列号之前！

在如上图所示的 TCP 连接中，服务端发送的 SEQ = 301 消息由于网络延迟直到 TCP 连接关闭后也没有收到；当使用相同端口号的 TCP 连接被重用后，SEQ = 301 的消息才发送到客户端，然而这个过期的消息却可能被客户端正常接收，这就会带来比较严重的问题，所以我们在调整 TIME_WAIT 策略时要非常谨慎，必须清楚自己在干什么。

### 为啥是2倍的MSL
RFC 793 中虽然指出了 TCP 连接需要在 TIME_WAIT 中等待 2 倍的 MSL，但是并没有解释清楚这里的两倍是从何而来，比较合理的解释是 — 网络中可能存在来自发起方的数据段，当这些发起方的数据段被服务端处理后又会向客户端发送响应，所以一来一回需要等待 2 倍的时间

> 原因一：如果没有等到足够长的时间，服务器在连接正常的时候发送的数据包，延迟达到新的连接上，造成严重后果。服务端处于ESTABLTSHED正常阶段

在 Linux 上，客户端的可以使用端口号 32,768 ~ 61,000，总共 28,232 个端口号与远程服务器建立连接，应用程序可以在将近 3 万的端口号中任意选择一个：

## 保证连接关闭
从 RFC 793 对 TIME_WAIT 状态的定义中，我们可以发现该状态的另一个重要作用，等待足够长的时间以确定远程的 TCP 连接接收到了其发出的终止连接消息 FIN 对应的 ACK：

如果客户端等待的时间不够长，当服务端还没有收到 ACK 消息时，客户端就重新与服务端建立 TCP 连接就会造成以下问题 — 服务端因为没有收到 ACK 消息，所以仍然认为当前连接是合法的，客户端重新发送 SYN 消息请求握手时会收到服务端的 RST 消息，连接建立的过程就会被终止。

只要客户端等待 2 MSL 的时间，客户端和服务端之间的连接就会正常关闭，新创建的 TCP 连接收到影响的概率也微乎其微，保证了数据传输的可靠性。

> 原因二：也就是如果不等待，同样的端口发起新的连接，但是服务端还认为之前的连接还存在，因为没有收到最后的ack确认。导致新建立的连接出错，如果等待足够长的时间，就能极大避免这个场景。服务端在LAST_ACK阶段

## 总结

在某些场景下，60 秒的等待销毁时间确实是难以接受的，例如：高并发的压力测试。当我们通过并发请求测试远程服务的吞吐量和延迟时，本地就可能产生大量处于 TIME_WAIT 状态的 TCP 连接

当我们在主机上通过几千个并发来测试服务器的压力时，这些用于压力测试的连接会迅速消耗主机上的 TCP 连接资源，几乎所有的 TCP 都会处于 TIME_WAIT 状态等待销毁。如果我们真遇到不得不处理单机上的 TIME_WAIT 状态的时候，那么可以通过以下几种方法处理：

- 使用 SO_LINGER 选项并设置暂存时间 l_linger 为 0，在这时如果我们关闭 TCP 连接，内核就会直接丢弃缓冲区中的全部数据并向服务端发送 RST 消息直接终止当前的连接[^7]；
- 使用 net.ipv4.tcp_tw_reuse 选项，通过 TCP 的时间戳选项允许内核重用处于 TIME_WAIT 状态的 TCP 连接[^8]；
- 修改 net.ipv4.ip_local_port_range 选项中的可用端口范围，增加可同时存在的 TCP 连接数上限；

如果客户端等待的时间不够长，那么使用相同端口号重新与远程建立连接时会造成以下问题：

- 因为数据段的网络传输时间不确定，所以可能会收到上一次 TCP 连接中未被收到的数据段；
- 因为客户端发出的 ACK 可能还没有被服务端接收，服务端可能还处于 LAST_ACK 状态，所以它会回复 RST 消息终止新连接的建立；
