- [redis基础](https://juejin.im/post/5db66ed9e51d452a2f15d833)


## Redis分布式锁

先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。
如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？
这个锁就永远得不到释放了。set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的！

- [大家所推崇的 Redis 分布式锁，真的万无一失吗？](https://juejin.im/post/5d41c94bf265da03a715b18f)

## 搜索指令

Redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，**但是会有一定的重复概率，在客户端做一次去重就可以了**，但是整体所花费的时间会比直接用keys指令长。
不过，增量式迭代命令也不是没有缺点的： 举个例子， 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素， 但是对于 SCAN 这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令只能对被返回的元素提供有限的保证 。

---
# 持久化

## Redis是怎么持久化的？服务主从数据怎么交互的？

RDB做镜像全量持久化，AOF做增量持久化。因为RDB会**耗费较长时间，不够实时**，在停机的时候会导致大量丢失数据，所以需要AOF来配合使用。在redis实例重启时，会使用RDB持久化文件**重新构建内存**，再使用AOF**重放近期的操作指令**来实现完整恢复重启之前的状态。

取决于AOF日志**sync属性的配置**，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。

你给出两个词汇就可以了，fork和cow。fork是指redis通过创建子进程来进行RDB操作，cow指的是**copy on write**，**子进程创建后，父子进程共享数据段**，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。

----
# Redis哨兵、持久化、主从、手撕LRU
- [Redis哨兵、持久化、主从、手撕LRU](https://juejin.im/post/5dc3a9fbf265da4d3c072eab)

## RDB/AOF

RDB
### 优点
他会生成**多个数据文件**，每个数据文件分别都代表了**某一时刻Redis里面的数据**，这种方式，有没有觉得很适合做**冷备**，完整的数据运维设置定时任务，定时同步到远端的服务器，比如阿里的云服务，这样一旦线上挂了，你想恢复多少分钟之前的数据，就去远端拷贝一份之前的数据就好了。
RDB对Redis的性能**影响非常小**，是因为在同步数据的时候他只是**fork了一个子进程去做持久化**的，而且他在数据**恢复的时候速度**比AOF来的快。

### 缺点
RDB都是快照文件，都是默认五分钟甚至更久的时间才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部**丢失**掉。AOF则最多丢一秒的数据，数据完整性上高下立判。
还有就是RDB在生成数据快照的时候，如果**文件很大**，客户端可能会暂停几毫秒甚至几秒，你公司在做秒杀的时候他刚好在这个时候fork了一个子进程去生成一个大快照，哦豁，出大问题。

AOF
### 优点
上面提到了，RDB五分钟一次生成快照，但是AOF是一秒一次去通过一个**后台的线程fsync操作**，那最多丢这一秒的数据。

AOF在对日志文件进行操作的时候是以append-only的方式去写的，他只是**追加的方式写数据**，自然就少了很多磁盘寻址的开销了，写入性能惊人，文件也不容易破损。

AOF的日志是通过一个叫**非常可读的方式记录**的，这样的特性就适合做灾难性数据误删除的紧急恢复了，比如公司的实习生通过flushall清空了所有的数据，只要这个时候后台重写还没发生，你马上拷贝一份AOF日志文件，把最后一条flushall命令删了就完事了。

### 缺点
一样的数据，AOF文件比RDB还要**大**。

AOF开启后，Redis支持写的**QPS会比RDB支持写的要低**，他不是每秒都要去异步刷新一次日志嘛fsync，当然即使这样性能还是很高，我记得ElasticSearch也是这样的，异步刷新缓存区的数据去持久化

---

## Redis的同步机制了解么

Redis可以使用**主从同步，从从同步**。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将RDB文件全量同步到复制节点，复制节点接受完成后将RDB镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。后续的增量数据通过AOF日志同步即可，有点类似数据库的binlog。

## 是否使用过Redis集群，集群的高可用怎么保证，集群的原理是什么？

Redis Sentinal 着眼于**高可用**，**在master宕机时会自动将slave提升为master**，继续提供服务。

Redis Cluster 着眼于**扩展性**，**在单个redis内存不足时，使用Cluster进行分片存储**。

## 哨兵

虽然上面redis做了备份，看上去很完美。但由于redis目前只支持主从复制备份（不支持主主复制），当主redis挂了，**从redis只能提供读服务，无法提供写服务**。所以，还得想办法，当主redis挂了，让从redis升级成为主redis。

哨兵组件的主要功能：

- 集群监控：负责监控 Redis master 和 slave 进程是否正常工作。
- 消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
- 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。
- 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。

---

## 过期策略

Redis的过期策略，是有定期删除+惰性删除两种。

定期好理解，默认100ms就随机抽一些设置了过期时间的key，去检查是否过期，过期了就删了。

### 为啥不扫描全部设置了过期时间的key呢？

假如Redis里面所有的key都有过期时间，都扫描一遍？那太恐怖了，而且我们线上基本上也都是会设置一定的过期时间的。全扫描跟你去查数据库不带where条件不走索引全表扫描一样，100ms一次，Redis累都累死了。

### 如果一直没随机到很多key，里面不就存在大量的无效key了？

好问题，惰性删除，见名知意，惰性嘛，我不主动删，我懒，我**等你来查询了我看看你过期没**，过期就删了还不给你返回，没过期该怎么样就怎么样。

## 内存淘汰
官网上给到的内存淘汰机制是以下几个：

- noeviction: 返回错误。当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）
- allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。
- volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。
- allkeys-random: 回收随机的键使得新添加的数据有空间存放。
- volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。
- volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。

---

- [Redis双写一致性、并发竞争、线程模型](https://juejin.im/post/5dc850b4e51d452c2308ee27)

## 操作（并发）Redis

### 分布式锁

某个时刻，多个系统实例都去更新某个 key。可以基于 Zookeeper 实现分布式锁。每个系统通过 Zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 Key，别人都不允许读和写。

### mvcc
你要写入缓存的数据，都是从 MySQL 里查出来的，都得写入 MySQL 中，写入 MySQL 中的时候必须保存一个时间戳，从 MySQL 查出来的时候，时间戳也查出来。

每次要写之前，先判断一下当前这个 Value 的时间戳是否比缓存里的 Value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。

- [数据一致性的问题](../web/缓存.md)


---
# Pipelining

Redis是一个CS结构的TCP服务器，使用”请求-应答”的模式。，客户端发起一个请求是这样的步骤：

客户端发送一个请求给服务器，然后等待服务器的响应，一般客户端使用阻塞模式来等待服务器响应。
服务器收到请求并处理完毕后，发送结果给客户端。


客户端和服务器通过网络连接，网速可以非常快, 也可以非常慢。不管是快还是慢，消息包从客户端到服务器，再从服务器返回到客户端，总是要需要时间的。这个时间被称之为**RTT(Round Trip Time，往返延时)**。显然，当客户端需要发送多条请求时（比如往一个list中加很多元素，或者往一个数据库中填充很多keys），这个往返延时会影响到性能。假设网络非常慢，往返延时达到250毫秒，就算服务器每秒可以处理10万个请求，客户端也只能每秒处理4个请求。就算使用环回接口，往返延时非常小，如果需要执行很多写的操作, 也是要浪费许多时间的。

“请求-响应”模式的服务器在处理完一个请求后就开始处理下一个请求，不管客户端是否读取到前一个请求的响应结果。这让**客户端不需要发一个请求等一个响应的串行，可以一次发送多个请求，再最后一次性读取所有响应。这就叫piplining（管道化）**，这种技术几十年来广泛的使用。比如很多POP3协议支持这个特性，大大的加速了从服务器上下载新邮件的速度。

Redis在很早的版本就支持pipeling，所以无论你用的是什么版本的redis，都可以用pipeling。下面是一个使用netcat的演示例子：

> 注意：当客户端使用pipelining发送很多请求时，服务器将在内存中使用队列存储这些指令的响应。所以批量发送的指令数量，最好在一个合理的范围内，比如每次发1万条指令，读取完响应后再发送另外1万条指令。2万条指令，一次性发送和分2次发送，对客户端来说速度是差不多的，但是对服务器来说，内存占用差了1万条响应的大小。


## 管道化 VS 脚本

大部分使用pipelining的情况都可以用Redis脚本（2.6或高于2.6的版本才支持）来代替，使之更高效的在服务器端执行。使用脚本的最大好处是，在最小的延迟下可以读和写，比如可以：让“读，计算，写”这样一个流程非常快(pipeling不能处理这种情景,因为客户端需要得到响应之后才能计算和写)。有时候，应用程序可能需要在一个pipeline中发送多个EVAL或EVALSHA指令，redis的SCRITP LOAD指令能很好的满足这种需求（它保证了EVALSHA不会有调用失败的风险）。

- [pipelining](https://ifeve.com/redis-pipelining/)
- [pipelining官方](https://github.com/antirez/redis-doc/blob/master/topics/pipelining.md)

## 管道和事务

流水线主要是一种网络优化。它本质上意味着客户端缓冲一堆命令，并一次性将它们发送到服务器。这些**命令不能保证在事务中执行。这样做的好处是节省了每个命令的网络往返时间**。

> 命令不能保证在事务中执行

Redis是单线程的，因此单个命令总是原子的，但是来自不同客户机的两个给定命令可以顺序执行，例如在它们之间交替执行。

但是，Multi/exec确保没有其他客户机在Multi/exec序列中的命令之间执行命令。

- [pipelining vs transaction in redis](https://stackoverflow.com/a/29337358)
- [Pipelines and Multiplexers](https://stackexchange.github.io/StackExchange.Redis/PipelinesMultiplexers.html)
