# Redis深度历险：核心原理和应用实践

标签（空格分隔）： 未分类

---

# 应用 1：千帆竞发 —— 分布式锁

注意锁不释放问题：setnx 和 expire 是两条指令而不是原子指令，也不能通过事务来解决，因为 expire 是依赖于 setnx 的执行结果的，如果 setnx 没抢到锁，expire 是不应该执行的。2.8版本支持：`set lock:codehole true ex 5 nx OK`组合原子指令。

注意超时问题：其他线程释放不是自己线程的锁，通过设置随机value来校验。注意：匹配和删除也需要进行原子性的操作，通过LUA脚本。

可重入性问题：需要对**客户端的 set 方法进行包装**，使用线程的 Threadlocal 变量存储当前持有锁的计数。 添加客户端的复杂性，不推荐使用。

---
# 应用 2：缓兵之计 —— 延时队列

不可靠：Redis 的消息队列不是专业的消息队列，它没有非常多的高级特性，
没有 ack 保证，如果对消息的可靠性有着极致的追求，那么它就不适合使用。

使用redis的list数据结构，并且通过lpop/rpop操作队列，但pop当队列时空的时候，可能会导致忙等待，导致CPU过高

阻塞读在队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来。消息的延迟几乎为零。用blpop/brpop替代前面的lpop/rpop，就完美解决了上面的问题。

如果线程一直阻塞在哪里，Redis 的客户端连接就成了闲置连接，闲置过久，服务器一般会主动断开连接，减少闲置资源占用。这个时候 blpop/brpop会抛出异常，注意异常处理。

延迟队列：延时队列可以通过 Redis 的 zset(有序列表) 来实现。我们将消息序列化成一个字符串作为 zset 的 value，这个消息的到期处理时间作为 score，然后用多个线程轮询 zset 获取到期的任务进行处理，多个线程是为了保障可用性，万一挂了一个线程还有其它线程可以继续处理。因为有多个线程，所以需要考虑并发争抢任务，确保任务不能被多次执行。
Redis 的 zrem 方法是多线程多进程争抢任务的关键，它的返回值决定了当前实例有没有抢到任务，因为 loop 方法可能会被多个线程、多个进程调用，同一个任务可能会被多个进程线程抢到，通过 zrem 来决定唯一的属主

上面的算法中同一个任务可能会被多个进程取到之后再使用 zrem 进行争抢，那些没抢到的进程都是白取了一次任务，这是浪费。可以考虑使用 lua scripting 来优化一下这个逻辑，将zrangebyscore 和 zrem 一同挪到服务器端进行原子化操作，这样多个进程之间争抢任务时就不会出现这种浪费了。

> 获取第一条，但是要避免多线程的抢占，所以通过zrem 获取到的值，来判断移除是否成功，能进行抢占的操作。最好是写成lua脚本获取，避免抢占浪费，保证获取到值肯定能删掉。抢占到了但消费可能会出错，所以这个队列时不可靠的。

# 应用 3：节衣缩食 —— 位图

Redis 的位数组是自动扩展，如果设置了某个偏移位置超出了现有的内容范围，就会自动将位数组进行零扩充

「零存」就是使用 setbit对位值进行逐个设置，「整存」就是使用字符串一次性填充所有位数组，覆盖掉旧值。

bitcount 用来统计指定位置范围内 1 的个数，bitpos 用来查找指定范围内出现的第一个 0 或 1。start 和 end 参数是字节索引，也就是说指定的位范围必须是 8 的倍数，
而不能任意指定。bitfield 有三个子指令，分别是get/set/incrby，它们都可以对指定位片段进行读写，但是最多只能处理 64 个连续的位，如果超过 64 位，就得使用多个子指令，bitfield 可以一次执行多个子指令。

```
bitcount w 0 1 # 前两个字符中 1 的位数
bitpos w 1 2 2 # 从第三个字符算起，第一个 1 位
bitfield w set u8 8 97 # 从第 8 个位开始，将接下来的 8 个位用无符号数 97 替换
bitfield w incrby u4 2 1 # 从第三个位开始，对接下来的 4 位无符号数 +1
```

---
# 应用 4：四两拨千斤 —— HyperLogLog

HyperLogLog 提供不精确的去重计数方案，虽然不精确但是也不是非常不
精确，标准误差是 0.81%，这样的精确度已经可以满足上面的 UV 统计需求了。

pfadd 用法和 set 集合的 sadd 是一样的，来一个用户 ID，就将用户 ID 塞进去就是。pfcount和scard用法是一样的，直接获取计数值。pfmerge，用于将多个 pf 计数值累加在一起形成一个新的 pf 值。

Redis 对 HyperLogLog的存储进行了优化，在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间。

给定一系列的随机整数，我们记录下低位连续零位的最大长度 k，通过这个 k 值可以估算出随机数的数量。

> TODO: 原理比较复杂，没看懂

---
# 应用 6：断尾求生 —— 简单限流

每一个行为到来时，都维护一次时间窗口。将时间窗口外的记录全部清理掉，只保留窗口内的记录。

```
# 记录行为
pipe.zadd(key, now_ts, now_ts) # value 和 score 都使用毫秒时间戳
# 移除时间窗口之前的行为记录，剩下的都是时间窗口内的
pipe.zremrangebyscore(key, 0, now_ts - period * 1000)
# 获取窗口内的行为数量
pipe.zcard(key)
```

---
# 应用 7：一毛不拔 —— 漏斗限流

Funnel 对象的 make_space 方法是漏斗算法的核心，其在每次灌水前都会被调用以触发漏水，给漏斗腾出空间来。能腾出多少空间取决于过去了多久以及流水的速率。Funnel 对象占据的空间大小不再和行为的频率成正比，它的空间占用是一个常量。

但是有个问题，我们无法保证整个过程的原子性。从hash结构中取值，然后在内存里运算，再回填到hash结构，这三个过程无法原子化，意味着需要进行适当的加锁控制。而一旦加锁，就意味着会有加锁失败，加锁失败就需要选择重试或者放弃.

Redis 4.0 提供了一个限流Redis模块，它叫redis-cell。该模块也使用了漏斗算法，并提供了原子的限流指令。
在执行限流指令时，如果被拒绝了，就需要丢弃或重试。cl.throttle 指令考虑的非常周到，连重试时间都帮你算好了，直接取返回结果数组的第四个值进行 sleep 即可，如果不想阻塞线程，也可以异步定时任务来重试。

```
cl.throttle laoqian:reply 15 30 60
```

> 每次请求的时候，判断上一次的漏出时间戳，然后添加剩余空间，再判断剩余空间是否足够。 TODO：cell底层实现。

---
# 应用 9：大海捞针 —— Scan

keys 算法是遍历算法，复杂度是 O(n)，如果实例中有千万级以上的 key，这个指令就会导致 Redis 服务卡顿，所有读写 Redis 的其它的指令都会被延后甚至会超时报错，因为Redis 是单线程程序，顺序执行所有指令，其它指令必须等到当前的 keys 指令执行完了才可以继续。

limit 不是限定返回结果的数量，而是限定服务器单次遍历的字典槽位数量

scan 的遍历顺序非常特别。它不是从第一维数组的第 0 位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是**考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏**

> 扩容和缩容对scan命令的影响。

很精妙：扩容相当于高位+1

011 => 1011 (011+ 8)
然后直接遍历**1011后**的数据就可以了。

缩容则不太一样。011缩成11，会忽略了111的遍历，所以要**重新遍历11**的的数据

## 大key
这样的对象对 Redis 的集群数据迁移带来了很大的问题，因为在集群环境下，如果某个 key 太大，会数据导致迁移卡顿。另外在内存分配上，如果一个 key 太大，那么当它需要扩容时，会一次性申请更大的一块内存，这也会导致卡顿。如果这个大 key 被删除，内存会一次性回收，卡顿现象会再一次产生。

如果你观察到 Redis 的**内存大起大落**，这极有可能是因为大 key 导致的，这时候你就需要定位出具体是那个 key，进一步定位出具体的业务来源，然后再改进相关业务代码设计。

定位：`redis-cli -h 127.0.0.1 -p 7001 –-bigkeys -i 0.1`
上面这个指令每隔 100 条 scan 指令就会休眠 0.1s，ops 就不会剧烈抬升，但是扫描的时间会变长

## 原理 1：鞭辟入里 —— 线程 IO 模型

**莫要瞧不起单线程，除了 Redis 之外，Node.js 也是单线程，Nginx 也是单线程，但是它们都是服务器高性能的典范。**

Redis 同样也会为每个客户端套接字关联一个响应队列。Redis 服务器通过响应队列来将指令的返回结果回复给客户端。 如果队列为空，那么意味着连接暂时处于空闲状态，不需要去获取写事件，也就是可以将当前的客户端描述符从 write_fds 里面移出来。等到队列有数据了，再将描述符放进去。避免 select 系统调用立即返回写事件，结果发现没什么数据可以写。出这种情况的线程会飙高 CPU。
> 响应队列关联客户端，当队列有响应的时候，才将写描述符关联，避免一直监听写事件（一般都是可写）但没数据可写。

Redis 的定时任务会记录在一个称为**最小堆**的数据结构中。这个堆中，最快要执行的任
务排在堆的最上方。在每个循环周期，Redis 都会将最小堆里面已经到点的任务立即进行处理。处理完毕后，将最快要执行的任务还需要的时间记录下来，这个时间就是 select 系统调用的 timeout 参数。因为 Redis 知道未来 timeout 时间内，没有其它定时任务需要处理，所以可以安心睡眠 timeout 的时间。
Nginx 和 Node 的事件处理原理和 Redis 也是类似的

> 最新版已经是最小堆吗？还是链表？跟Redis设计与实现有不同。不过获取最新的定时事件来作为sleep是一样的。node、Nginx的定时也是类似

---
# 拓展 5：优胜劣汰 —— LRU

allkey-xxx、volatile-xxx 淘汰策略。

实现 LRU 算法除了需要 key/value 字典外，还需要附加一个链表，链表中的元素按照
一定的顺序进行排列。当空间满的时候，会踢掉链表尾部的元素。当字典的某个元素被访问时，它在链表中的位置会被移动到表头。所以链表的元素排列顺序就是元素最近被访问的时间顺序

> LRU实现算法：dict、链表。表头移动。 一个Python的例子： OrderedDict支持顺序，所以类似一个链表。popitem(last=True)来进行最后的元素移除。

## 近似 LRU 算法

Redis 为实现近似 LRU 算法，它给每个 key 增加了一个额外的小字段，这个字段的长度是 24 个 bit，也就是最后一次被访问的时间戳

近似LRU算法，避免大量额外的内存：
这个算法也很简单，就是随机采样出 5(可以配置) 个 key，然后淘汰掉最
旧的 key，如果淘汰后内存还是超出maxmemory，那就继续随机采样淘汰，直到内存低于maxmemory 为止。

从图中可以看出采样数量越大，近似 LRU 算法的效果越接近严格 LRU 
算法。同时 Redis3.0 在算法中增加了淘汰池，进一步提升了近似 LRU 算法的效果。

采样数量越大，越近似。

淘汰池：新算法会维护一个候选池（大小为16），池中的数据根据访问时间进行排序，第一次随机选取的key都会放入池中，随后每次随机选取的key只有在访问时间小于池中最小的时间才会放入池中，直到候选池被放满。当放满后，如果有新的key需要放入，则将池中最后访问时间最大（最近被访问）的移除。

TODO：有啥作用提升了算法效果？
每次随机5个，淘汰一个最旧的。但是淘汰池会保存所有随机的最旧的16个，增加旧key的淘汰几率。

---
# 拓展 6：平波缓进 —— 懒惰删除

Redis 为了解决这个卡顿问题，在 4.0 版本引入了 unlink 指令，它能对删除操作进行懒处理，丢给后台线程来异步回收内存

> unlink的线程安全问题：已经不能访问到了。标记为删除。

flushdb 和 flushall 指令：Redis 4.0 同样给这两个指令也带来了异步化，在指令后面增加 async 参数就可以将整棵大树连根拔起，扔给后台线程慢慢焚烧。

主线程封装异步操作到异步任务队列，后台线程从异步队列取任务。任务队列被主线程和异步线程同时操作，所以必须是一个线程安全的队列。

执行 AOF Sync 操作的线程是一个独立的异步线程，和前面的懒惰删除线
程不是一个线程，同样它也有一个属于自己的任务队列，队列里只用来存放 AOF Sync 任务。

Redis 回收内存除了 del 指令和 flush 之外，还会存在于在 key 的过期、LRU 淘汰、
rename 指令以及从库全量同步时接受完 rdb 文件后会立即进行的 flush 操作。

---

总结：这本书相当于工作中的老师，很希望把redis的特性简单明了，由浅入深得跟你说清楚，并且都立于应用与实际。受益匪浅。而且每一个章节最后的参考链接都很有帮助，看得出作者希望我们能学习更多。




