tag: 冷热隔离 压缩


这种模式很容易理解并且易于实现，但是它粉饰了索引管理的一些复杂的地方：

- 为了达到较高的写入速度，活跃索引分片需要分布在尽可能多的节点上。
- 为了提高搜索速度和降低资源消耗，分片数量需要尽可能地少，但是也不能有过大的单个分片进而不便操作（重建非活跃索引的分片数、强制合并和压缩）
- 一天一个索引确实易于清理陈旧数据，但是一天到底需要多少个分片呢？（指定活跃索引的分片数）
- 每天的写入压力是一成不变的吗？还是一天分片过多，而下一天分片不够用呢？（rollover支持更改索引默认值）



# 滚动模式
滚动模式工作流程如下：

- 有一个用于写入的索引别名，其指向活跃索引
- 另外一个用于读取（搜索）的索引别名，指向不活跃索引
- 活跃索引具有和热节点数量一样多的分片，可以充分发挥昂贵硬件的索引写入能力
- 当活跃索引太满或者太老的时候，它就会滚动：新建一个索引并且索引别名自动从老索引切换到新索引
- 移动老索引到冷节点上并且缩小为一个分片，之后可以强制合并和压缩。


----

```shell script

PUT _template/active-logs
{
  "template": "active-logs-*",
  "aliases": {
    "active-logs": {}, 
    "search-logs": {}
  }
}

PUT _template/inactive-logs
{
  "template": "inactive-logs-*", 
  "settings": { 
    "number_of_shards": 1, 
    "number_of_replicas": 0,
    "routing.allocation.include.box_type": "cold",
    "codec": "best_compression"
  }
}

PUT active-logs-1

POST active-logs/log/_bulk
{ "create": {}} { "text": "Some log message", "@timestamp": "2016-07-01T01:00:00Z" }
{ "create": {}} { "text": "Some log message", "@timestamp": "2016-07-02T01:00:00Z" }
{ "create": {}} { "text": "Some log message", "@timestamp": "2016-07-03T01:00:00Z" }
{ "create": {}} { "text": "Some log message", "@timestamp": "2016-07-04T01:00:00Z" }
{ "create": {}} { "text": "Some log message", "@timestamp": "2016-07-05T01:00:00Z" }

# 滚动索引
POST active-logs/_rollover
{
  "conditions": {
    "max_age": "7d",
    "max_docs": 5
  }
}

# result
{
  "old_index": "active-logs-1",
  "new_index": "active-logs-2",
  "rolled_over": true,
  "dry_run": false,
  "conditions": {
    "[max_docs: 5]": true,
    "[max_age: 7d]": false
  }
}

# 缩小索引
PUT active-logs-1/_settings
{
  "index.blocks.write": true,
  "index.routing.allocation.require._name": "some_node_name"
}

POST active-logs-1/_shrink/inactive-logs-1


GET _cluster/health/inactive-logs-1?wait_for_status=yellow

POST _aliases
{
  "actions": [
    {
      "remove": {
        "index": "active-logs-1",
        "alias": "search-logs"
      } 
    },
    {
      "add": {
        "index": "inactive-logs-1",
        "alias": "search-logs"
      }
    }
  ]
}


# 我们的索引已经缩小到单个分片，但它依旧包含和之前相同数量的段文件，并且 best_compression 设置并没有生效，因为没有任何写入操作。我们可以用强制合并来将单分片索引优化为单分段索引，如下：
POST inactive-logs-1/_forcemerge?max_num_segments=1


# 在主分片和复制分片上分别运行强制合并是没有意义的，这就是为什么我们的非活跃索引模板中 number_of_replicas 设置被为 0。现在当强制合并结束后，我们可以打开复制分片以获得冗余：
PUT inactive-logs-1/_settings
{ "number_of_replicas": 1 }


DELETE active-logs-1

# 字段统计, 我们只需要具有找出超过我们阈值的最大 @timestamp 字段的索引列表进行删除
GET search-logs/_field_stats?level=indices
{
  "fields": ["@timestamp"],
  "index_constraints": {
    "@timestamp": {
      "max_value": {
        "lt": "2016/07/03",
        "format": "yyyy/MM/dd"
      }
    }
  }
}

```

active-logs-1 过期，rollover创建一个active-logs-2新的index，并将active-logs别名指向该新的索引。

search-log 指向active-logs-1与active-logs-2，write index 会将旧的is_write_index设为false并设新的设为true，以保证新的写入是写到新的索引active-logs-2里面。

然后对active-logs-1进行缩小索引，合成一个分片，并理由_shrink重建到inactive-logs-1上（没有启动副本）。重建完后进行索引别名重建

search-logs删除active-logs-1，但是添加inactive-logs-1。然后通过强制合并，将单分片索引优化为单分段索引。最后添加冗余副本，删除旧索引。

active-logs-1  和inactive-logs-1 通过标签进行不同机器的冷热部署。


本地测试的结论：
active_logs/rollover后，只是把ag_active_logs的别名索引移除，并没有将search-log的索引移除
search-log 指向active-logs-1与active-logs-2
active_logs 仅仅指向active-logs-2

> 名字规范： -\d 会主动往左补充0进行直到长度为6

```shell script

PUT _template/active_logs
{
  "template": "ag_active_logs-*",
  "aliases": {
    "ag_active_logs": {}, 
    "ag_search_logs": {}
  }
}

PUT ag_active_logs-1

POST ag_active_logs/log/_bulk
{ "index": {}}
{ "doc": {"text": "Some log message", "@timestamp": "2016-07-01T01:00:00Z" } }


POST ag_active_logs/_rollover
{
  "conditions": {
    "max_age": "7d",
    "max_docs": 5
  }
}
```

- [高效管理 Elasticsearch 中基于时间的索引](https://juejin.im/post/5a990cdbf265da239b40de65)
- https://elasticsearch.apachecn.org/#/docs/191